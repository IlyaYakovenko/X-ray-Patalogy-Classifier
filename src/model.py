import torch.nn as nn
import torch
from torchvision import models
from torchvision.models import ResNet50_Weights


class ChestXRayModel(nn.Module):
    def __init__(self, num_classes=15, pretrained=True, freeze_backbone=True):
        super().__init__()
        self.num_classes = num_classes
        self.pretrained = pretrained
        self.freeze_backbone = freeze_backbone

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        if self.pretrained:
            weights = ResNet50_Weights.IMAGENET1K_V2
            self.backbone = models.resnet50(weights=weights)
            print("‚úì –ó–∞–≥—Ä—É–∂–µ–Ω—ã –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ ImageNet")
        else:
            self.backbone = models.resnet50(weights=None)
            print("‚úì –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏")

        # –ó–∞–º–æ—Ä–æ–∑–∫–∞ —Å–ª–æ–µ–≤
        if self.freeze_backbone and self.pretrained:
            for param in self.backbone.parameters():
                param.requires_grad = False
            print("‚úì –í—Å–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —Å–ª–æ–∏ –∑–∞–º–æ—Ä–æ–∂–µ–Ω—ã")

        # –ó–∞–º–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è
        num_ftrs = self.backbone.fc.in_features
        self.backbone.fc = nn.Linear(num_ftrs, self.num_classes)

        # –†–∞–∑–º–æ—Ä–æ–∑–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è
        for param in self.backbone.fc.parameters():
            param.requires_grad = True

        print(f"‚úì –ó–∞–º–µ–Ω–µ–Ω –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π: {num_ftrs} -> {self.num_classes} –Ω–µ–π—Ä–æ–Ω–æ–≤")

        self.diseases = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.to(self.device)
        self._print_model_info()

    def forward(self, x):
        return self.backbone(x)

    def _print_model_info(self):
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        print(f"\nüìä –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ü–ê–†–ê–ú–ï–¢–†–ê–•:")
        print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
        print(f"–û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {trainable_params:,} ({trainable_params / total_params * 100:.1f}%)")

    def setup_training(self, learning_rate=0.001, optimizer_type='adam',
                       weight_decay=1e-4):

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
        self.diseases = self.diseases  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑–≤–Ω–µ

        # –í—ã–±–∏—Ä–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å (–±–µ–∑ –≤–µ—Å–æ–≤!)

        criterion = nn.BCEWithLogitsLoss()
        loss_name = "BCEWithLogitsLoss"

        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        trainable_params = [p for p in self.parameters() if p.requires_grad]
        if optimizer_type == 'adam':
            optimizer = torch.optim.Adam(trainable_params, lr=learning_rate, weight_decay=weight_decay)
        elif optimizer_type == 'sgd':
            optimizer = torch.optim.SGD(trainable_params, lr=learning_rate, momentum=0.9)
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: {optimizer_type}")

        print(f"\n‚úì –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è:")
        print(f"  - –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: {optimizer_type} (lr={learning_rate}, weight_decay={weight_decay})")
        print(f"  - –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å: {loss_name}")

        return optimizer, criterion

    def save_model(self, filepath):
        torch.save(self.state_dict(), filepath)
        print(f"‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filepath}")

    def load_model(self, filepath):
        self.load_state_dict(torch.load(filepath, map_location=self.device))
        self.to(self.device)
        print(f"‚úì –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {filepath}")
