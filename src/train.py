import os
import time
import json

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import torch
from torch.utils.data import DataLoader
from sklearn.metrics import roc_auc_score


import albumentations as A
from albumentations.pytorch import ToTensorV2

from src.data import BalancedAugmentationChestXRayDataset, ChestXRayDataset
from src.model import ChestXRayModel


class Trainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self._create_directories()

        self.model = None
        self.optimizer = None
        self.criterion = None
        self.train_loader = None
        self.val_loader = None

        self.history = {
            'train_loss': [], 'val_loss': [], 'val_auc': [],
            'val_macro_f1': [], 'val_micro_f1': [], 'learning_rates': []
        }

        print("üéØ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –¢–†–ï–ù–ï–†–ê")
        print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {json.dumps(config, indent=2)}")

    def _create_directories(self):
        os.makedirs('/content/drive/MyDrive/X-ray/outputs/models', exist_ok=True)
        os.makedirs('/content/drive/MyDrive/X-ray/outputs/figures', exist_ok=True)
        os.makedirs('/content/drive/MyDrive/X-ray/outputs/logs', exist_ok=True)

    def setup_data(self):
        print("\nüìä –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•")

        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
        train_transform = A.Compose([
            A.HorizontalFlip(p=0.5),
            A.Rotate(limit=10, p=0.3),
            A.RandomBrightnessContrast(p=0.2),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2(),
        ])

        val_transform = A.Compose([
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2(),
        ])

        # –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
        train_dataset = BalancedAugmentationChestXRayDataset(
            csv_path='/content/drive/MyDrive/X-ray/data/train_labels.csv',
            transform=train_transform
        )

        # –î–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –±–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
        val_dataset = ChestXRayDataset(
            csv_path='/content/drive/MyDrive/X-ray/data/val_labels.csv',
            transform=val_transform
        )

        self.train_loader = DataLoader(
            train_dataset,
            batch_size=self.config['batch_size'],
            shuffle=True,
            num_workers=self.config['num_workers'],
            pin_memory=True
        )

        self.val_loader = DataLoader(
            val_dataset,
            batch_size=self.config['batch_size'],
            shuffle=False,
            num_workers=self.config['num_workers'],
            pin_memory=True
        )

        self.diseases = train_dataset.diseases
        print(f"‚úì –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –Ω–∞–±–æ—Ä: {len(train_dataset)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        print(f"‚úì –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä: {len(val_dataset)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

    def setup_model(self):
        print("\nü§ñ –ù–ê–°–¢–†–û–ô–ö–ê –ú–û–î–ï–õ–ò")

        self.model = ChestXRayModel(
            num_classes=len(self.diseases),
            pretrained=self.config['pretrained'],
            freeze_backbone=self.config['freeze_backbone']
        )

        # –ü–µ—Ä–µ–¥–∞–µ–º diseases –≤ –º–æ–¥–µ–ª—å
        self.model.diseases = self.diseases

        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ (–±–µ–∑ –≤–µ—Å–æ–≤!)
        self.optimizer, self.criterion = self.model.setup_training(
            learning_rate=self.config['learning_rate'],
            optimizer_type=self.config['optimizer'],
            weight_decay=self.config.get('weight_decay', 1e-4)
        )

        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='max', factor=0.5, patience=3
        )

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    def train_epoch(self):
        self.model.train()
        running_loss = 0.0
        num_batches = 0

        for batch_idx, (images, labels) in enumerate(self.train_loader):
            images, labels = images.to(self.device), labels.to(self.device)

            self.optimizer.zero_grad()
            outputs = self.model(images)
            loss = self.criterion(outputs, labels)
            loss.backward()
            self.optimizer.step()

            running_loss += loss.item()
            num_batches += 1

            if batch_idx % 100 == 0:
                current_lr = self.optimizer.param_groups[0]['lr']
                print(f"  –ë–∞—Ç—á {batch_idx}/{len(self.train_loader)}, –ü–æ—Ç–µ—Ä—è: {loss.item():.4f}")

        return running_loss / num_batches

    def validate_epoch(self):
        self.model.eval()
        running_loss = 0.0
        all_preds, all_labels = [], []

        with torch.no_grad():
            for images, labels in self.val_loader:
                images, labels = images.to(self.device), labels.to(self.device)
                outputs = self.model(images)
                loss = self.criterion(outputs, labels)
                preds = torch.sigmoid(outputs)

                all_preds.append(preds.cpu().numpy())
                all_labels.append(labels.cpu().numpy())
                running_loss += loss.item()

        all_preds = np.vstack(all_preds)
        all_labels = np.vstack(all_labels)

        val_loss = running_loss / len(self.val_loader)
        val_auc = self.calculate_auc(all_labels, all_preds)
        threshold = self.config.get('threshold', 0.3)
        macro_f1, micro_f1 = self.calculate_f1(all_labels, all_preds, threshold)

        print("\nüìä AUC –ø–æ –∫–ª–∞—Å—Å–∞–º:")
        auc_scores = []
        for i, disease in enumerate(self.diseases):
            try:
                auc = roc_auc_score(all_labels[:, i], all_preds[:, i])
                auc_scores.append(auc)

                if auc > 0.7:
                    print(f"‚úÖ {disease}: {auc:.4f}")
                elif auc < 0.6:
                    print(f"‚ö†Ô∏è  {disease}: {auc:.4f}")
                else:
                    print(f"   {disease}: {auc:.4f}")
            except ValueError:
                auc_scores.append(0.5)
                print(f"‚ùå {disease}: –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å AUC")

        return val_loss, val_auc, macro_f1, micro_f1

    def calculate_auc(self, labels, preds):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–∏–π AUC –ø–æ –≤—Å–µ–º –∫–ª–∞—Å—Å–∞–º."""
        auc_scores = []
        for i in range(labels.shape[1]):
            if len(np.unique(labels[:, i])) >= 2:
                try:
                    auc = roc_auc_score(labels[:, i], preds[:, i])
                    auc_scores.append(auc)
                except ValueError:
                    auc_scores.append(0.5)
        return np.mean(auc_scores) if auc_scores else 0.5

    def calculate_f1(self, labels, preds, threshold=0.3):
        from sklearn.metrics import f1_score, classification_report
        binary_preds = (preds > threshold).astype(int)
        macro_f1 = f1_score(labels, binary_preds, average='macro', zero_division=0)
        micro_f1 = f1_score(labels, binary_preds, average='micro', zero_division=0)

        if labels.shape[1] <= 15:
            print(classification_report(labels, binary_preds, target_names=self.diseases, zero_division=0))

        return macro_f1, micro_f1

    def save_checkpoint(self, epoch, is_best=False):
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'history': self.history,
            'config': self.config,
            'diseases': self.diseases
        }

        checkpoint_path = f"/content/drive/MyDrive/X-ray/outputs/models/checkpoint_epoch_{epoch}.pth"
        torch.save(checkpoint, checkpoint_path)

        if is_best:
            best_model_path = "/content/drive/MyDrive/X-ray/outputs/models/best_model.pth"
            torch.save(self.model.state_dict(), best_model_path)
            print(f"‚úì –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {best_model_path}")

    def plot_training_history(self):
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

        ax1.plot(self.history['train_loss'], label='Train Loss')
        ax1.plot(self.history['val_loss'], label='Val Loss')
        ax1.set_title('Training and Validation Loss')
        ax1.legend()
        ax1.grid(True)

        ax2.plot(self.history['val_auc'], label='Val AUC', color='green')
        ax2.set_title('Validation AUC')
        ax2.legend()
        ax2.grid(True)

        ax3.plot(self.history['val_macro_f1'], label='Val Macro F1', color='orange')
        ax3.plot(self.history['val_micro_f1'], label='Val Micro F1', color='red')
        ax3.set_title('Validation F1-Scores')
        ax3.legend()
        ax3.grid(True)

        ax4.plot(self.history['learning_rates'], label='Learning Rate', color='red')
        ax4.set_title('Learning Rate Schedule')
        ax4.set_yscale('log')
        ax4.legend()
        ax4.grid(True)

        plt.tight_layout()
        plt.savefig('/content/drive/MyDrive/X-ray/outputs/figures/training_history.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("‚úì –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")

    def train(self):
        print("\nüöÄ –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø")
        print("=" * 60)

        self.setup_data()
        self.setup_model()

        best_auc = 0.0
        start_time = time.time()

        for epoch in range(1, self.config['num_epochs'] + 1):
            epoch_start = time.time()

            print(f"\nüìÖ –≠–ü–û–•–ê {epoch}/{self.config['num_epochs']}")
            print("-" * 50)

            train_loss = self.train_epoch()
            val_loss, val_auc, macro_f1, micro_f1 = self.validate_epoch()

            current_lr = self.optimizer.param_groups[0]['lr']
            self.scheduler.step(val_auc)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
            self.history['train_loss'].append(train_loss)
            self.history['val_loss'].append(val_loss)
            self.history['val_auc'].append(val_auc)
            self.history['val_macro_f1'].append(macro_f1)
            self.history['val_micro_f1'].append(micro_f1)
            self.history['learning_rates'].append(current_lr)

            print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –≠–ü–û–•–ò {epoch}:")
            print(f"  Train Loss: {train_loss:.4f}")
            print(f"  Val Loss:   {val_loss:.4f}")
            print(f"  Val AUC:    {val_auc:.4f}")
            print(f"  Val F1:     Macro: {macro_f1:.4f}, Micro: {micro_f1:.4f}")
            print(f"  Learning Rate: {current_lr:.6f}")
            print(f"  –í—Ä–µ–º—è —ç–ø–æ—Ö–∏: {time.time() - epoch_start:.2f} —Å–µ–∫")

            if epoch % 5 == 0:
                self.save_checkpoint(epoch)

            if val_auc > best_auc:
                best_auc = val_auc
                self.save_checkpoint(epoch, is_best=True)
                print(f"üéâ –ù–û–í–´–ô –†–ï–ö–û–†–î! AUC: {best_auc:.4f}")

        total_time = time.time() - start_time
        print(f"\n‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –∑–∞ {total_time / 60:.1f} –º–∏–Ω")
        print(f"–õ—É—á—à–∞—è AUC: {best_auc:.4f}")

        self.plot_training_history()
        self.save_checkpoint(self.config['num_epochs'])

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥–∏
        history_df = pd.DataFrame(self.history)
        history_df.to_csv('/content/drive/MyDrive/X-ray/outputs/logs/training_history.csv', index=False)

        with open('/content/drive/MyDrive/X-ray/outputs/logs/training_config.json', 'w') as f:
            json.dump(self.config, f, indent=2)

        print("‚úì –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")


TRAINING_CONFIG = {
    'num_epochs': 10,
    'batch_size': 128,
    'learning_rate': 0.00982119621793305,
    'image_size': 224,
    'pretrained': True,
    'freeze_backbone': True,
    'optimizer': 'adam',
    'num_workers': 2,
    'threshold': 0.1,
    'weight_decay': 1.7744079336785624e-05,
    # –£–±—Ä–∞–ª–∏ max_weight –∏ augmentation_multiplier, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω—ã
}

print("ü©∫ –¢–†–ï–ù–ò–†–û–í–ö–ê –ú–û–î–ï–õ–ò –î–õ–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –†–ï–ù–¢–ì–ï–ù–û–í–°–ö–ò–• –°–ù–ò–ú–ö–û–í")
print("=" * 70)

trainer = Trainer(TRAINING_CONFIG)

try:
    trainer.train()
except KeyboardInterrupt:
    print("\n‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
except Exception as e:
    print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {e}")
    raise